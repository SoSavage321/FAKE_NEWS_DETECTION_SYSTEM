{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f63d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_modeling.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load the cleaned dataset\"\"\"\n",
    "    print(\"Loading cleaned dataset...\")\n",
    "    df = pd.read_csv('cleaned_news_dataset.csv')\n",
    "    print(f\"‚úÖ Dataset loaded: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def prepare_features(df):\n",
    "    \"\"\"Prepare features and target variable\"\"\"\n",
    "    X = df['combined_text']\n",
    "    y = df['label']\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"üìä Data split:\")\n",
    "    print(f\"   Training set: {X_train.shape[0]:,} samples\")\n",
    "    print(f\"   Test set: {X_test.shape[0]:,} samples\")\n",
    "    print(f\"   Fake news in train: {y_train.value_counts()[0]:,}\")\n",
    "    print(f\"   True news in train: {y_train.value_counts()[1]:,}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_and_evaluate_models(X_train, y_train):\n",
    "    \"\"\"Train and evaluate multiple ML models\"\"\"\n",
    "    \n",
    "    # Define models with their pipelines\n",
    "    models = {\n",
    "        'Logistic Regression': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')),\n",
    "            ('lr', LogisticRegression(random_state=42, max_iter=1000))\n",
    "        ]),\n",
    "        'Random Forest': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')),\n",
    "            ('rf', RandomForestClassifier(random_state=42, n_estimators=100))\n",
    "        ]),\n",
    "       \n",
    "    }\n",
    "    \n",
    "    # Evaluate models with cross-validation\n",
    "    results = {}\n",
    "    print(\"\\nü§ñ Training and evaluating models...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for name, pipeline in models.items():\n",
    "        # Cross-validation scores\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='f1')\n",
    "        \n",
    "        # Train the model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        results[name] = {\n",
    "            'pipeline': pipeline,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'cv_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        print(f\"{name:20} | F1 Score: {cv_scores.mean():.4f} (¬±{cv_scores.std()*2:.4f})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def select_best_model(results, X_train, y_train):\n",
    "    \"\"\"Select the best performing model\"\"\"\n",
    "    best_model_name = max(results.keys(), key=lambda x: results[x]['cv_mean'])\n",
    "    best_model = results[best_model_name]['pipeline']\n",
    "    \n",
    "    print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "    print(f\"üèÜ Cross-validation F1 Score: {results[best_model_name]['cv_mean']:.4f}\")\n",
    "    \n",
    "    return best_model, best_model_name\n",
    "\n",
    "def hyperparameter_tuning(X_train, y_train):\n",
    "    \"\"\"Perform hyperparameter tuning for the best model\"\"\"\n",
    "    print(\"\\nüéØ Performing hyperparameter tuning...\")\n",
    "    \n",
    "    # Parameter grid for Logistic Regression\n",
    "    param_grid = {\n",
    "        'tfidf__max_features': [3000, 5000, 7000],\n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "        'lr__C': [0.1, 1.0, 10.0],\n",
    "        'lr__penalty': ['l2']  # l1 requires solver like liblinear\n",
    "    }\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "        ('lr', LogisticRegression(random_state=42, max_iter=1000, solver='liblinear'))\n",
    "    ])\n",
    "    \n",
    "    # Grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, \n",
    "        param_grid, \n",
    "        cv=5, \n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"‚úÖ Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"‚úÖ Best CV score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def evaluate_final_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate the final model on test set\"\"\"\n",
    "    print(\"\\nüìä Final Model Evaluation on Test Set\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    \n",
    "    print(f\"\\nüìã Detailed Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Fake', 'True']))\n",
    "    \n",
    "    return y_pred, y_pred_proba\n",
    "\n",
    "def save_model(model, model_name):\n",
    "    \"\"\"Save the trained model\"\"\"\n",
    "    filename = f'{model_name.replace(\" \", \"_\").lower()}_model.pkl'\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"‚úÖ Model saved as: {filename}\")\n",
    "    return filename\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for ML modeling\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ü§ñ MACHINE LEARNING MODELING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    df = load_data()\n",
    "    X_train, X_test, y_train, y_test = prepare_features(df)\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    results = train_and_evaluate_models(X_train, y_train)\n",
    "    \n",
    "    # Select best model\n",
    "    best_model, best_model_name = select_best_model(results, X_train, y_train)\n",
    "    \n",
    "    # Hyperparameter tuning\n",
    "    tuned_model = hyperparameter_tuning(X_train, y_train)\n",
    "    \n",
    "    # Evaluate both models\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Original Best Model:\")\n",
    "    y_pred_orig, y_proba_orig = evaluate_final_model(best_model, X_test, y_test)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Tuned Model:\")\n",
    "    y_pred_tuned, y_proba_tuned = evaluate_final_model(tuned_model, X_test, y_test)\n",
    "    \n",
    "    # Save models\n",
    "    orig_model_file = save_model(best_model, f\"original_{best_model_name}\")\n",
    "    tuned_model_file = save_model(tuned_model, f\"tuned_{best_model_name}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Modeling completed!\")\n",
    "    print(f\"   Original model: {orig_model_file}\")\n",
    "    print(f\"   Tuned model: {tuned_model_file}\")\n",
    "    \n",
    "    return tuned_model, X_test, y_test\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, X_test, y_test = main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

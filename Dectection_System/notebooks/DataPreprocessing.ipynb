{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dcea4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\phill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\phill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\phill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05dae739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Fake dataset shape: (23481, 4)\n",
      "True dataset shape: (21417, 4)\n",
      "\n",
      "Fake dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23481 entries, 0 to 23480\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    23481 non-null  object\n",
      " 1   text     23481 non-null  object\n",
      " 2   subject  23481 non-null  object\n",
      " 3   date     23481 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 733.9+ KB\n",
      "None\n",
      "\n",
      "True dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21417 entries, 0 to 21416\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    21417 non-null  object\n",
      " 1   text     21417 non-null  object\n",
      " 2   subject  21417 non-null  object\n",
      " 3   date     21417 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 669.4+ KB\n",
      "None\n",
      "\n",
      "Fake dataset columns: ['title', 'text', 'subject', 'date']\n",
      "True dataset columns: ['title', 'text', 'subject', 'date']\n"
     ]
    }
   ],
   "source": [
    "# Load both datasets\n",
    "print(\"Loading datasets...\")\n",
    "try:\n",
    "    fake_df = pd.read_csv(r'C:\\Users\\phill\\Downloads\\Dectection_System\\data\\Fake.csv')\n",
    "    true_df = pd.read_csv(r'C:\\Users\\phill\\Downloads\\Dectection_System\\data\\True.csv')\n",
    "    \n",
    "    print(\"Fake dataset shape:\", fake_df.shape)\n",
    "    print(\"True dataset shape:\", true_df.shape)\n",
    "    \n",
    "    # Display basic info about both datasets\n",
    "    print(\"\\nFake dataset info:\")\n",
    "    print(fake_df.info())\n",
    "    print(\"\\nTrue dataset info:\")\n",
    "    print(true_df.info())\n",
    "    \n",
    "    print(\"\\nFake dataset columns:\", fake_df.columns.tolist())\n",
    "    print(\"True dataset columns:\", true_df.columns.tolist())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    print(\"Please ensure both 'Fake.csv' and 'True.csv' are in the current directory\")\n",
    "    # Create sample data for demonstration\n",
    "    fake_df = pd.DataFrame({\n",
    "        'title': ['Breaking: Shocking conspiracy theory exposed!'],\n",
    "        'text': ['This unbelievable revelation will change everything you know!'],\n",
    "        'subject': ['conspiracy'],\n",
    "        'date': ['December 31, 2017']\n",
    "    })\n",
    "    true_df = pd.DataFrame({\n",
    "        'title': ['Scientific study shows positive results'],\n",
    "        'text': ['Researchers conducted a thorough analysis of the data.'],\n",
    "        'subject': ['science'],\n",
    "        'date': ['January 15, 2018']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2168b356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EXPLORING FAKE DATASET\n",
      "==================================================\n",
      "Shape: (23481, 4)\n",
      "Columns: ['title', 'text', 'subject', 'date']\n",
      "\n",
      "Missing values:\n",
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "dtype: int64\n",
      "\n",
      "Subject distribution:\n",
      "subject\n",
      "News               9050\n",
      "politics           6841\n",
      "left-news          4459\n",
      "Government News    1570\n",
      "US_News             783\n",
      "Middle-east         778\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample titles:\n",
      "1.  Donald Trump Sends Out Embarrassing New Year’s Eve Message; This is Disturbing\n",
      "2.  Drunk Bragging Trump Staffer Started Russian Collusion Investigation\n",
      "3.  Sheriff David Clarke Becomes An Internet Joke For Threatening To Poke People ‘In The Eye’\n",
      "4.  Trump Is So Obsessed He Even Has Obama’s Name Coded Into His Website (IMAGES)\n",
      "5.  Pope Francis Just Called Out Donald Trump During His Christmas Speech\n",
      "\n",
      "Text length - Mean: 2547, Std: 2533\n",
      "Title length - Mean: 94, Std: 27\n",
      "Word count - Mean: 423, Std: 408\n",
      "\n",
      "==================================================\n",
      "EXPLORING TRUE DATASET\n",
      "==================================================\n",
      "Shape: (21417, 4)\n",
      "Columns: ['title', 'text', 'subject', 'date']\n",
      "\n",
      "Missing values:\n",
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "dtype: int64\n",
      "\n",
      "Subject distribution:\n",
      "subject\n",
      "politicsNews    11272\n",
      "worldnews       10145\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample titles:\n",
      "1. As U.S. budget fight looms, Republicans flip their fiscal script\n",
      "2. U.S. military to accept transgender recruits on Monday: Pentagon\n",
      "3. Senior U.S. Republican senator: 'Let Mr. Mueller do his job'\n",
      "4. FBI Russia probe helped by Australian diplomat tip-off: NYT\n",
      "5. Trump wants Postal Service to charge 'much more' for Amazon shipments\n",
      "\n",
      "Text length - Mean: 2383, Std: 1685\n",
      "Title length - Mean: 65, Std: 9\n",
      "Word count - Mean: 386, Std: 274\n"
     ]
    }
   ],
   "source": [
    "def explore_dataset(df, dataset_name):\n",
    "    \"\"\"Explore basic statistics of a dataset\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"EXPLORING {dataset_name.upper()} DATASET\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    print(\"\\nMissing values:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    print(\"\\nSubject distribution:\")\n",
    "    print(df['subject'].value_counts())\n",
    "    \n",
    "    print(\"\\nSample titles:\")\n",
    "    for i, title in enumerate(df['title'].head(5)):\n",
    "        print(f\"{i+1}. {title}\")\n",
    "    \n",
    "    # Basic text statistics\n",
    "    df['text_length'] = df['text'].apply(lambda x: len(str(x)))\n",
    "    df['title_length'] = df['title'].apply(lambda x: len(str(x)))\n",
    "    df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n",
    "    \n",
    "    print(f\"\\nText length - Mean: {df['text_length'].mean():.0f}, Std: {df['text_length'].std():.0f}\")\n",
    "    print(f\"Title length - Mean: {df['title_length'].mean():.0f}, Std: {df['title_length'].std():.0f}\")\n",
    "    print(f\"Word count - Mean: {df['word_count'].mean():.0f}, Std: {df['word_count'].std():.0f}\")\n",
    "\n",
    "# Explore both datasets\n",
    "explore_dataset(fake_df, \"FAKE\")\n",
    "explore_dataset(true_df, \"TRUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d20bc5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing fake dataset...\n",
      "Preprocessing true dataset...\n",
      "Preprocessing completed!\n"
     ]
    }
   ],
   "source": [
    "def enhanced_clean_text(text):\n",
    "    \"\"\"\n",
    "    Enhanced text cleaning and preprocessing\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to string and lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove social media elements\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # Remove special characters and numbers but keep basic punctuation for context\n",
    "    text = re.sub(r'[^\\w\\s\\.\\,\\!\\?]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Lemmatize and remove stopwords\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens \n",
    "              if token not in stop_words and len(token) > 2]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def extract_features(df):\n",
    "    \"\"\"\n",
    "    Extract comprehensive features from the dataset\n",
    "    \"\"\"\n",
    "    # Text cleaning\n",
    "    df['cleaned_text'] = df['text'].apply(enhanced_clean_text)\n",
    "    df['cleaned_title'] = df['title'].apply(enhanced_clean_text)\n",
    "    \n",
    "    # Combined features\n",
    "    df['combined_text'] = df['cleaned_title'] + ' ' + df['cleaned_text']\n",
    "    \n",
    "    # Numerical features\n",
    "    df['text_length'] = df['text'].apply(lambda x: len(str(x)))\n",
    "    df['title_length'] = df['title'].apply(lambda x: len(str(x)))\n",
    "    df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n",
    "    df['avg_word_length'] = df['text'].apply(lambda x: np.mean([len(word) for word in str(x).split()]) \n",
    "                                            if len(str(x).split()) > 0 else 0)\n",
    "    \n",
    "    # Sentiment indicators (simple version)\n",
    "    df['has_exclamation'] = df['title'].apply(lambda x: 1 if '!' in str(x) else 0)\n",
    "    df['has_question'] = df['title'].apply(lambda x: 1 if '?' in str(x) else 0)\n",
    "    df['title_uppercase_ratio'] = df['title'].apply(\n",
    "        lambda x: sum(1 for c in str(x) if c.isupper()) / max(1, len(str(x)))\n",
    "    )\n",
    "    \n",
    "    # Date features\n",
    "    df['has_date'] = df['date'].apply(lambda x: 1 if pd.notna(x) and str(x).strip() != '' else 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Preprocessing fake dataset...\")\n",
    "fake_df = extract_features(fake_df)\n",
    "fake_df['label'] = 0  # 0 for fake news\n",
    "\n",
    "print(\"Preprocessing true dataset...\")\n",
    "true_df = extract_features(true_df)\n",
    "true_df['label'] = 1  # 1 for true news\n",
    "\n",
    "print(\"Preprocessing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b090d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (44898, 16)\n",
      "Fake news count: 23481\n",
      "True news count: 21417\n",
      "Duplicate rows: 209\n",
      "Dataset shape after removing duplicates: (44689, 16)\n"
     ]
    }
   ],
   "source": [
    "# Combine datasets\n",
    "combined_df = pd.concat([fake_df, true_df], ignore_index=True)\n",
    "\n",
    "print(f\"Combined dataset shape: {combined_df.shape}\")\n",
    "print(f\"Fake news count: {len(combined_df[combined_df['label'] == 0])}\")\n",
    "print(f\"True news count: {len(combined_df[combined_df['label'] == 1])}\")\n",
    "\n",
    "# Check for any duplicates\n",
    "print(f\"Duplicate rows: {combined_df.duplicated().sum()}\")\n",
    "\n",
    "# Remove duplicates if any\n",
    "combined_df = combined_df.drop_duplicates()\n",
    "print(f\"Dataset shape after removing duplicates: {combined_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a02f1119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned dataset saved as: C:\\Users\\phill\\Downloads\\Dectection_System\\data\\cleaned_news_dataset.csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Cleaned dataset saved as: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcleaned_data_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Save the vectorizer and label encoder if needed\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m joblib.dump(\u001b[43mtfidf_vectorizer\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mtfidf_vectorizer.pkl\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ TF-IDF vectorizer saved\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Also save the train-test split indices for consistency\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'tfidf_vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset for use in separate files\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Save the cleaned dataset\n",
    "cleaned_data_path = r'C:\\Users\\phill\\Downloads\\Dectection_System\\data\\cleaned_news_dataset.csv'\n",
    "combined_df.to_csv(cleaned_data_path, index=False)\n",
    "print(f\"✅ Cleaned dataset saved as: {cleaned_data_path}\")\n",
    "\n",
    "# Save the vectorizer and label encoder if needed\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n",
    "print(\"✅ TF-IDF vectorizer saved\")\n",
    "\n",
    "# Also save the train-test split indices for consistency\n",
    "split_data = {\n",
    "    'X_train': X_train.index.tolist(),\n",
    "    'X_test': X_test.index.tolist(),\n",
    "    'y_train': y_train.index.tolist(), \n",
    "    'y_test': y_test.index.tolist()\n",
    "}\n",
    "joblib.dump(split_data, 'train_test_split.pkl')\n",
    "print(\"✅ Train-test split indices saved\")\n",
    "\n",
    "# Display dataset info\n",
    "print(f\"\\n📊 CLEANED DATASET INFO:\")\n",
    "print(f\"Total samples: {len(combined_df):,}\")\n",
    "print(f\"Fake news: {len(combined_df[combined_df['label'] == 0]):,}\")\n",
    "print(f\"True news: {len(combined_df[combined_df['label'] == 1]):,}\")\n",
    "print(f\"Features: {combined_df.shape[1]}\")\n",
    "print(f\"File size: {cleaned_data_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

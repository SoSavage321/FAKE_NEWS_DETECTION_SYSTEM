{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbfe7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìä STATISTICAL ANALYSIS & EVALUATION\n",
      "============================================================\n",
      "Loading model and test data...\n",
      "‚úÖ Model and data loaded\n",
      "üìä Test set: 8,938 samples\n",
      "üîç Model type: LogisticRegression\n",
      "\n",
      "============================================================\n",
      "üìä HYPOTHESIS TESTING - MODEL PERFORMANCE\n",
      "============================================================\n",
      "üìà Model Performance Metrics:\n",
      "   Accuracy:  0.9950\n",
      "   Precision: 0.9948\n",
      "   Recall:    0.9946\n",
      "   F1 Score:  0.9947\n",
      "\n",
      "üîç Hypothesis Test 1: Accuracy vs Random Guessing\n",
      "   Baseline accuracy (majority class): 0.5254\n",
      "   Model accuracy: 0.9950\n",
      "   Z-score: 88.9016\n",
      "   P-value: 0.0000\n",
      "   ‚úÖ REJECT H0: Model performs significantly better than random guessing\n",
      "\n",
      "üîç Hypothesis Test 2: Precision vs Recall Balance\n",
      "   Precision: 0.9948, Recall: 0.9946\n",
      "   Absolute difference: 0.0002\n",
      "   P-value for difference: 0.8291\n",
      "   ‚ùå No significant difference between precision and recall\n",
      "\n",
      "============================================================\n",
      "üìä CONFIDENCE INTERVALS FOR PERFORMANCE METRICS\n",
      "============================================================\n",
      "95% Confidence Intervals (Bootstrap):\n",
      "   Accuracy  : 0.9950 [0.9935, 0.9965]\n",
      "   Precision : 0.9948 [0.9926, 0.9969]\n",
      "   Recall    : 0.9946 [0.9923, 0.9967]\n",
      "   F1        : 0.9947 [0.9931, 0.9963]\n",
      "   AUC        : 0.9998 [0.9997, 0.9999]\n",
      "\n",
      "============================================================\n",
      "üîç MODEL ASSUMPTION VALIDATION\n",
      "============================================================\n",
      "Model type: LogisticRegression\n",
      "üìà Logistic Regression Assumption Checks:\n",
      "1. Feature Independence Check:\n",
      "   Average mutual information: 0.0076\n",
      "   Max mutual information: 0.6540\n",
      "\n",
      "2. Multicollinearity Check:\n",
      "   Condition number of feature matrix: 1.16e+67\n",
      "   ‚ö†Ô∏è  High condition number indicates potential multicollinearity\n",
      "\n",
      "============================================================\n",
      "üîç FEATURE IMPORTANCE ANALYSIS\n",
      "============================================================\n",
      "Top Features by Coefficient Magnitude:\n",
      "--------------------------------------------------\n",
      " 1. reuters              | Coef: 53.2621 (+) | Importance: 53.2621\n",
      " 2. said                 | Coef: 20.6085 (+) | Importance: 20.6085\n",
      " 3. washington reuters   | Coef: 19.5230 (+) | Importance: 19.5230\n",
      " 4. video                | Coef: -13.9311 (-) | Importance: 13.9311\n",
      " 5. read                 | Coef: -13.5044 (-) | Importance: 13.5044\n",
      " 6. image                | Coef: -12.5526 (-) | Importance: 12.5526\n",
      " 7. president donald     | Coef: 10.9456 (+) | Importance: 10.9456\n",
      " 8. president trump      | Coef: -10.8471 (-) | Importance: 10.8471\n",
      " 9. breaking             | Coef: -10.6803 (-) | Importance: 10.6803\n",
      "10. featured image       | Coef: -10.5848 (-) | Importance: 10.5848\n",
      "11. reuters president    | Coef: 9.9736 (+) | Importance: 9.9736\n",
      "12. gop                  | Coef: -9.8612 (-) | Importance: 9.8612\n",
      "13. featured             | Coef: -9.6971 (-) | Importance: 9.6971\n",
      "14. hillary              | Coef: -9.5258 (-) | Importance: 9.5258\n",
      "15. thats                | Coef: 8.9311 (+) | Importance: 8.9311\n",
      "16. obama                | Coef: -8.4671 (-) | Importance: 8.4671\n",
      "17. nov                  | Coef: 7.5212 (+) | Importance: 7.5212\n",
      "18. mr                   | Coef: -7.4335 (-) | Importance: 7.4335\n",
      "19. wednesday            | Coef: 7.2172 (+) | Importance: 7.2172\n",
      "20. watch                | Coef: -7.1411 (-) | Importance: 7.1411\n",
      "\n",
      "Calculating permutation importance...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_model_and_data():\n",
    "    \"\"\"Load the trained model and test data\"\"\"\n",
    "    print(\"Loading model and test data...\")\n",
    "    \n",
    "    try:\n",
    "        base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    except NameError:\n",
    "        base_dir = os.getcwd()\n",
    "\n",
    "    # ‚úÖ Go up one level from 'notebooks' to project root\n",
    "    project_root = os.path.abspath(os.path.join(base_dir, \"..\"))\n",
    "\n",
    "    model_path = os.path.join(project_root, 'models', 'original_random_forest_model.pkl')\n",
    "    data_path = os.path.join(project_root, 'data', 'cleaned_news_dataset.csv')\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"‚ùå Model file not found: {model_path}\")\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(f\"‚ùå Data file not found: {data_path}\")\n",
    "\n",
    "    model = joblib.load(model_path)\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Prepare features\n",
    "    X = df['combined_text']\n",
    "    y = df['label']\n",
    "    \n",
    "    # Split data (same random state as modeling)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Model and data loaded\")\n",
    "    print(f\"üìä Test set: {X_test.shape[0]:,} samples\")\n",
    "    print(f\"üîç Model type: {type(model.named_steps[list(model.named_steps.keys())[-1]]).__name__}\")\n",
    "    \n",
    "    return model, X_train, X_test, y_train, y_test\n",
    "\n",
    "def hypothesis_testing_performance(model, X_test, y_test):\n",
    "    \"\"\"Perform hypothesis testing on model performance\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä HYPOTHESIS TESTING - MODEL PERFORMANCE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get predictions and probabilities\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate key metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"üìà Model Performance Metrics:\")\n",
    "    print(f\"   Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"   Precision: {precision:.4f}\")\n",
    "    print(f\"   Recall:    {recall:.4f}\")\n",
    "    print(f\"   F1 Score:  {f1:.4f}\")\n",
    "    \n",
    "    # Hypothesis test: Is accuracy significantly better than random guessing?\n",
    "    print(f\"\\nüîç Hypothesis Test 1: Accuracy vs Random Guessing\")\n",
    "    \n",
    "    # Random guessing baseline (majority class)\n",
    "    baseline_accuracy = max(y_test.mean(), 1 - y_test.mean())\n",
    "    n_test = len(y_test)\n",
    "    \n",
    "    # Z-test for proportions\n",
    "    se = np.sqrt(baseline_accuracy * (1 - baseline_accuracy) / n_test)\n",
    "    z_score = (accuracy - baseline_accuracy) / se\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "    \n",
    "    print(f\"   Baseline accuracy (majority class): {baseline_accuracy:.4f}\")\n",
    "    print(f\"   Model accuracy: {accuracy:.4f}\")\n",
    "    print(f\"   Z-score: {z_score:.4f}\")\n",
    "    print(f\"   P-value: {p_value:.4f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(\"   ‚úÖ REJECT H0: Model performs significantly better than random guessing\")\n",
    "    else:\n",
    "        print(\"   ‚ùå FAIL TO REJECT H0: Model not significantly better than random guessing\")\n",
    "    \n",
    "    # Hypothesis test 2: Compare precision and recall\n",
    "    print(f\"\\nüîç Hypothesis Test 2: Precision vs Recall Balance\")\n",
    "    \n",
    "    # Test if precision and recall are significantly different\n",
    "    precision_recall_diff = abs(precision - recall)\n",
    "    pooled_se = np.sqrt((precision * (1 - precision) + recall * (1 - recall)) / n_test)\n",
    "    z_score_pr = precision_recall_diff / pooled_se\n",
    "    p_value_pr = 2 * (1 - stats.norm.cdf(abs(z_score_pr)))\n",
    "    \n",
    "    print(f\"   Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    print(f\"   Absolute difference: {precision_recall_diff:.4f}\")\n",
    "    print(f\"   P-value for difference: {p_value_pr:.4f}\")\n",
    "    \n",
    "    if p_value_pr < 0.05:\n",
    "        print(\"   ‚úÖ Significant difference between precision and recall\")\n",
    "    else:\n",
    "        print(\"   ‚ùå No significant difference between precision and recall\")\n",
    "    \n",
    "    return y_pred, y_pred_proba\n",
    "\n",
    "def confidence_intervals_metrics(y_test, y_pred, y_pred_proba):\n",
    "    \"\"\"Calculate confidence intervals for performance metrics\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä CONFIDENCE INTERVALS FOR PERFORMANCE METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Bootstrap confidence intervals\n",
    "    n_bootstraps = 500  # Reduced for speed\n",
    "    metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    \n",
    "    for i in range(n_bootstraps):\n",
    "        # Bootstrap sample\n",
    "        indices = resample(range(len(y_test)))\n",
    "        y_test_boot = y_test.iloc[indices]\n",
    "        y_pred_boot = y_pred[indices]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics['accuracy'].append(accuracy_score(y_test_boot, y_pred_boot))\n",
    "        metrics['precision'].append(precision_score(y_test_boot, y_pred_boot, zero_division=0))\n",
    "        metrics['recall'].append(recall_score(y_test_boot, y_pred_boot))\n",
    "        metrics['f1'].append(f1_score(y_test_boot, y_pred_boot))\n",
    "    \n",
    "    # Calculate 95% confidence intervals\n",
    "    print(\"95% Confidence Intervals (Bootstrap):\")\n",
    "    for metric_name, values in metrics.items():\n",
    "        ci_lower = np.percentile(values, 2.5)\n",
    "        ci_upper = np.percentile(values, 97.5)\n",
    "        mean_val = np.mean(values)\n",
    "        print(f\"   {metric_name.capitalize():10}: {mean_val:.4f} [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "    \n",
    "    # AUC confidence interval\n",
    "    auc_scores = []\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = resample(range(len(y_test)))\n",
    "        auc_scores.append(roc_auc_score(y_test.iloc[indices], y_pred_proba[indices]))\n",
    "    \n",
    "    auc_ci_lower = np.percentile(auc_scores, 2.5)\n",
    "    auc_ci_upper = np.percentile(auc_scores, 97.5)\n",
    "    auc_mean = np.mean(auc_scores)\n",
    "    \n",
    "    print(f\"   AUC        : {auc_mean:.4f} [{auc_ci_lower:.4f}, {auc_ci_upper:.4f}]\")\n",
    "\n",
    "def validate_model_assumptions(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Validate key assumptions for the model\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"üîç MODEL ASSUMPTION VALIDATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get the model type\n",
    "    model_type = type(model.named_steps[list(model.named_steps.keys())[-1]]).__name__\n",
    "    print(f\"Model type: {model_type}\")\n",
    "    \n",
    "    if model_type == 'RandomForestClassifier':\n",
    "        validate_rf_assumptions(model, X_train, X_test, y_train, y_test)\n",
    "    elif model_type == 'LogisticRegression':\n",
    "        validate_lr_assumptions(model, X_train, X_test, y_train, y_test)\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  Assumption validation not implemented for {model_type}\")\n",
    "\n",
    "def validate_rf_assumptions(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Validate assumptions for Random Forest\"\"\"\n",
    "    print(\"üå≤ Random Forest Assumption Checks:\")\n",
    "    \n",
    "    # Get the TF-IDF features and RF model\n",
    "    tfidf = model.named_steps['tfidf']\n",
    "    rf_model = model.named_steps['rf']\n",
    "    \n",
    "    # Transform the training data\n",
    "    X_train_tfidf = tfidf.transform(X_train)\n",
    "    \n",
    "    print(\"1. Feature Quality Check:\")\n",
    "    # Check for feature importance distribution\n",
    "    if hasattr(rf_model, 'feature_importances_'):\n",
    "        importances = rf_model.feature_importances_\n",
    "        print(f\"   Number of features with importance > 0.001: {np.sum(importances > 0.001)}\")\n",
    "        print(f\"   Top feature importance: {np.max(importances):.4f}\")\n",
    "        print(f\"   Mean feature importance: {np.mean(importances):.6f}\")\n",
    "    \n",
    "    print(\"\\n2. Out-of-Bag Error Check:\")\n",
    "    if hasattr(rf_model, 'oob_score_'):\n",
    "        print(f\"   OOB Score: {rf_model.oob_score_:.4f}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  OOB score not available (set oob_score=True during training)\")\n",
    "    \n",
    "    print(\"\\n3. Tree Depth Analysis:\")\n",
    "    tree_depths = [tree.tree_.max_depth for tree in rf_model.estimators_]\n",
    "    print(f\"   Average tree depth: {np.mean(tree_depths):.1f}\")\n",
    "    print(f\"   Max tree depth: {np.max(tree_depths)}\")\n",
    "    print(f\"   Min tree depth: {np.min(tree_depths)}\")\n",
    "    \n",
    "    print(\"\\n4. Prediction Confidence Analysis:\")\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    prediction_confidence = np.max(y_pred_proba, axis=1)\n",
    "    print(f\"   Average prediction confidence: {np.mean(prediction_confidence):.4f}\")\n",
    "    print(f\"   Low confidence predictions (<0.6): {np.sum(prediction_confidence < 0.6)}/{len(prediction_confidence)}\")\n",
    "\n",
    "def validate_lr_assumptions(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Validate assumptions for Logistic Regression\"\"\"\n",
    "    print(\"üìà Logistic Regression Assumption Checks:\")\n",
    "    \n",
    "    # Get the TF-IDF features and LR model\n",
    "    tfidf = model.named_steps['tfidf']\n",
    "    lr_model = model.named_steps['lr']\n",
    "    \n",
    "    # Transform the training data\n",
    "    X_train_tfidf = tfidf.transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    \n",
    "    print(\"1. Feature Independence Check:\")\n",
    "    from sklearn.feature_selection import mutual_info_classif\n",
    "    # Use a subset for faster computation\n",
    "    n_samples = min(1000, X_train_tfidf.shape[0])\n",
    "    X_subset = X_train_tfidf[:n_samples].toarray()\n",
    "    y_subset = y_train[:n_samples]\n",
    "    \n",
    "    mi_scores = mutual_info_classif(X_subset, y_subset, random_state=42)\n",
    "    print(f\"   Average mutual information: {np.mean(mi_scores):.4f}\")\n",
    "    print(f\"   Max mutual information: {np.max(mi_scores):.4f}\")\n",
    "    \n",
    "    print(\"\\n2. Multicollinearity Check:\")\n",
    "    # Use smaller subset for covariance calculation\n",
    "    n_samples_cov = min(500, X_train_tfidf.shape[0])\n",
    "    X_cov = X_train_tfidf[:n_samples_cov].toarray()\n",
    "    covariance_matrix = X_cov.T @ X_cov\n",
    "    condition_number = np.linalg.cond(covariance_matrix)\n",
    "    print(f\"   Condition number of feature matrix: {condition_number:.2e}\")\n",
    "    if condition_number > 1000:\n",
    "        print(\"   ‚ö†Ô∏è  High condition number indicates potential multicollinearity\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Condition number within acceptable range\")\n",
    "\n",
    "def analyze_feature_importance(model, X_train, X_test, y_train, y_test, top_n=20):\n",
    "    \"\"\"Comprehensive feature importance analysis\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"üîç FEATURE IMPORTANCE ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get model components\n",
    "    tfidf = model.named_steps['tfidf']\n",
    "    model_type = type(model.named_steps[list(model.named_steps.keys())[-1]]).__name__\n",
    "    \n",
    "    # Get feature names\n",
    "    try:\n",
    "        feature_names = tfidf.get_feature_names_out()\n",
    "    except:\n",
    "        feature_names = tfidf.get_feature_names()\n",
    "    \n",
    "    if model_type == 'RandomForestClassifier':\n",
    "        return analyze_rf_feature_importance(model, X_test, y_test, feature_names, top_n)\n",
    "    elif model_type == 'LogisticRegression':\n",
    "        return analyze_lr_feature_importance(model, X_test, y_test, feature_names, top_n)\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  Feature importance not implemented for {model_type}\")\n",
    "        return feature_names, None, None\n",
    "\n",
    "def analyze_rf_feature_importance(model, X_test, y_test, feature_names, top_n=20):\n",
    "    \"\"\"Feature importance analysis for Random Forest\"\"\"\n",
    "    rf_model = model.named_steps['rf']\n",
    "    tfidf = model.named_steps['tfidf']\n",
    "    \n",
    "    # 1. Built-in feature importance\n",
    "    if hasattr(rf_model, 'feature_importances_'):\n",
    "        importances = rf_model.feature_importances_\n",
    "        indices = np.argsort(importances)[-top_n:][::-1]\n",
    "        \n",
    "        print(\"Top Features by Random Forest Importance:\")\n",
    "        print(\"-\" * 55)\n",
    "        for i, idx in enumerate(indices[:top_n]):\n",
    "            print(f\"{i+1:2d}. {feature_names[idx]:20} | Importance: {importances[idx]:.4f}\")\n",
    "    \n",
    "    # 2. Permutation importance with sparse matrix handling\n",
    "    print(f\"\\nüîÑ Calculating Permutation Importance...\")\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    \n",
    "    # Convert sparse matrix to dense array for permutation importance\n",
    "    # Use a subset if the matrix is too large\n",
    "    n_samples_perm = min(1000, X_test_tfidf.shape[0])\n",
    "    X_test_dense = X_test_tfidf[:n_samples_perm].toarray()\n",
    "    y_test_subset = y_test[:n_samples_perm]\n",
    "    \n",
    "    try:\n",
    "        perm_importance = permutation_importance(\n",
    "            rf_model, X_test_dense, y_test_subset, \n",
    "            n_repeats=5,  # Reduced for speed\n",
    "            random_state=42,\n",
    "            scoring='f1',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Get top permutation importance features\n",
    "        perm_indices = np.argsort(perm_importance.importances_mean)[-top_n:][::-1]\n",
    "        \n",
    "        print(\"\\nTop Features by Permutation Importance:\")\n",
    "        print(\"-\" * 55)\n",
    "        for i, idx in enumerate(perm_indices[:10]):  # Show top 10\n",
    "            if idx < len(feature_names):  # Safety check\n",
    "                print(f\"{i+1:2d}. {feature_names[idx]:20} | Importance: {perm_importance.importances_mean[idx]:.4f} (¬±{perm_importance.importances_std[idx]:.4f})\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Permutation importance failed: {e}\")\n",
    "        perm_importance = None\n",
    "        perm_indices = []\n",
    "    \n",
    "    # Visualization for Random Forest\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Built-in importance plot\n",
    "    plt.subplot(2, 1, 1)\n",
    "    top_builtin_features = [feature_names[i] for i in indices[:15]]\n",
    "    top_builtin_values = [importances[i] for i in indices[:15]]\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(top_builtin_features)))\n",
    "    bars = plt.barh(range(len(top_builtin_features)), top_builtin_values, color=colors)\n",
    "    plt.yticks(range(len(top_builtin_features)), top_builtin_features)\n",
    "    plt.title('Random Forest - Top 15 Features (Built-in Importance)', fontweight='bold')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, bar in enumerate(bars):\n",
    "        plt.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "                f'{top_builtin_values[i]:.4f}', ha='left', va='center', fontsize=9)\n",
    "    \n",
    "    # Permutation importance plot (if available)\n",
    "    if perm_importance is not None and len(perm_indices) > 0:\n",
    "        plt.subplot(2, 1, 2)\n",
    "        top_perm_features = [feature_names[i] for i in perm_indices[:15] if i < len(feature_names)]\n",
    "        top_perm_values = [perm_importance.importances_mean[i] for i in perm_indices[:15] if i < len(feature_names)]\n",
    "        top_perm_std = [perm_importance.importances_std[i] for i in perm_indices[:15] if i < len(feature_names)]\n",
    "        \n",
    "        if top_perm_features:  # Check if we have any features to plot\n",
    "            colors = plt.cm.plasma(np.linspace(0, 1, len(top_perm_features)))\n",
    "            bars = plt.barh(range(len(top_perm_features)), top_perm_values, \n",
    "                           xerr=top_perm_std, color=colors, alpha=0.7)\n",
    "            plt.yticks(range(len(top_perm_features)), top_perm_features)\n",
    "            plt.title('Random Forest - Top 15 Features (Permutation Importance)', fontweight='bold')\n",
    "            plt.xlabel('Importance Score')\n",
    "            plt.gca().invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('random_forest_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return feature_names, importances, perm_importance\n",
    "\n",
    "def analyze_lr_feature_importance(model, X_test, y_test, feature_names, top_n=20):\n",
    "    \"\"\"Feature importance analysis for Logistic Regression\"\"\"\n",
    "    lr_model = model.named_steps['lr']\n",
    "    tfidf = model.named_steps['tfidf']\n",
    "    \n",
    "    # 1. Coefficient-based importance\n",
    "    coefficients = lr_model.coef_[0]\n",
    "    feature_importance = np.abs(coefficients)\n",
    "    \n",
    "    # Get top features\n",
    "    top_indices = np.argsort(feature_importance)[-top_n:][::-1]\n",
    "    \n",
    "    print(\"Top Features by Coefficient Magnitude:\")\n",
    "    print(\"-\" * 50)\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        sign = \"+\" if coefficients[idx] > 0 else \"-\"\n",
    "        print(f\"{i+1:2d}. {feature_names[idx]:20} | Coef: {coefficients[idx]:.4f} ({sign}) | Importance: {feature_importance[idx]:.4f}\")\n",
    "    \n",
    "    # 2. Permutation importance with sparse matrix handling\n",
    "    print(f\"\\nCalculating permutation importance...\")\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    \n",
    "    # Convert to dense array for permutation importance\n",
    "    n_samples_perm = min(1000, X_test_tfidf.shape[0])\n",
    "    X_test_dense = X_test_tfidf[:n_samples_perm].toarray()\n",
    "    y_test_subset = y_test[:n_samples_perm]\n",
    "    \n",
    "    try:\n",
    "        perm_importance = permutation_importance(\n",
    "            lr_model, X_test_dense, y_test_subset, \n",
    "            n_repeats=5,  # Reduced for speed\n",
    "            random_state=42,\n",
    "            scoring='f1'\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Permutation importance failed: {e}\")\n",
    "        perm_importance = None\n",
    "    \n",
    "    # Visualization for Logistic Regression\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Coefficient importance plot\n",
    "    top_coef_features = [feature_names[i] for i in top_indices[:15]]\n",
    "    top_coef_values = [coefficients[i] for i in top_indices[:15]]\n",
    "    \n",
    "    colors = ['green' if x > 0 else 'red' for x in top_coef_values]\n",
    "    bars = plt.barh(range(15), top_coef_values, color=colors)\n",
    "    plt.yticks(range(15), top_coef_features)\n",
    "    plt.title('Logistic Regression - Top 15 Features\\n(Green=True news, Red=Fake news)', fontweight='bold')\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, bar in enumerate(bars):\n",
    "        plt.text(bar.get_width() + 0.001 if bar.get_width() >= 0 else bar.get_width() - 0.01, \n",
    "                bar.get_y() + bar.get_height()/2, \n",
    "                f'{top_coef_values[i]:.4f}', ha='left' if bar.get_width() >= 0 else 'right', \n",
    "                va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return feature_names, coefficients, perm_importance\n",
    "\n",
    "def statistical_significance_features(model, X_test, y_test, feature_names):\n",
    "    \"\"\"Test statistical significance of feature importance\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä STATISTICAL SIGNIFICANCE OF FEATURES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    model_type = type(model.named_steps[list(model.named_steps.keys())[-1]]).__name__\n",
    "    \n",
    "    if model_type == 'LogisticRegression':\n",
    "        statistical_significance_lr_features(model, X_test, y_test, feature_names)\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  Statistical significance testing currently implemented for Logistic Regression only\")\n",
    "        print(f\"   For Random Forest, use built-in feature importance and permutation importance above\")\n",
    "\n",
    "def statistical_significance_lr_features(model, X_test, y_test, feature_names):\n",
    "    \"\"\"Test statistical significance for Logistic Regression features\"\"\"\n",
    "    tfidf = model.named_steps['tfidf']\n",
    "    lr_model = model.named_steps['lr']\n",
    "    \n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    coefficients = lr_model.coef_[0]\n",
    "    \n",
    "    # Calculate p-values for coefficients using bootstrap (with subset for speed)\n",
    "    n_bootstraps = 100  # Reduced for speed\n",
    "    boot_coefs = np.zeros((n_bootstraps, len(coefficients)))\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    # Use subset for bootstrap\n",
    "    n_samples_boot = min(1000, X_test_tfidf.shape[0])\n",
    "    X_boot_base = X_test_tfidf[:n_samples_boot].toarray()\n",
    "    y_boot_base = y_test[:n_samples_boot]\n",
    "    \n",
    "    for i in range(n_bootstraps):\n",
    "        # Bootstrap sample\n",
    "        indices = resample(range(len(X_boot_base)))\n",
    "        X_boot = X_boot_base[indices]\n",
    "        y_boot = y_boot_base.iloc[indices] if hasattr(y_boot_base, 'iloc') else y_boot_base[indices]\n",
    "        \n",
    "        # Fit logistic regression on bootstrap sample\n",
    "        boot_lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "        boot_lr.fit(X_boot, y_boot)\n",
    "        if len(boot_lr.coef_) > 0:\n",
    "            boot_coefs[i] = boot_lr.coef_[0]\n",
    "    \n",
    "    # Calculate p-values (two-tailed test)\n",
    "    p_values = []\n",
    "    for j in range(len(coefficients)):\n",
    "        # Count how often bootstrap coefficient has opposite sign or is zero\n",
    "        opposite_sign_count = np.sum(boot_coefs[:, j] * coefficients[j] <= 0)\n",
    "        p_value = opposite_sign_count / n_bootstraps\n",
    "        p_values.append(p_value)\n",
    "    \n",
    "    p_values = np.array(p_values)\n",
    "    \n",
    "    # Count significant features at different levels\n",
    "    alpha_levels = [0.05, 0.01, 0.001]\n",
    "    print(\"Feature Significance at Different Alpha Levels:\")\n",
    "    for alpha in alpha_levels:\n",
    "        significant_count = np.sum(p_values < alpha)\n",
    "        print(f\"   Œ± = {alpha}: {significant_count} significant features ({significant_count/len(p_values)*100:.1f}%)\")\n",
    "    \n",
    "    # Show most significant features\n",
    "    significant_indices = np.where(p_values < 0.05)[0]\n",
    "    if len(significant_indices) > 0:\n",
    "        print(f\"\\nTop 10 Most Statistically Significant Features (p < 0.05):\")\n",
    "        print(\"-\" * 60)\n",
    "        top_sig_indices = significant_indices[np.argsort(p_values[significant_indices])[:10]]\n",
    "        \n",
    "        for i, idx in enumerate(top_sig_indices):\n",
    "            if idx < len(feature_names):  # Safety check\n",
    "                print(f\"{i+1:2d}. {feature_names[idx]:20} | Coef: {coefficients[idx]:.4f} | p-value: {p_values[idx]:.4f}\")\n",
    "\n",
    "def create_comprehensive_report(model, X_test, y_test, y_pred, y_pred_proba):\n",
    "    \"\"\"Create a comprehensive statistical report\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"üìã COMPREHENSIVE STATISTICAL REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Model performance summary\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(\"üéØ MODEL PERFORMANCE SUMMARY:\")\n",
    "    print(f\"   ‚Ä¢ Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Precision: {precision:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Recall:    {recall:.4f}\")\n",
    "    print(f\"   ‚Ä¢ F1 Score:  {f1:.4f}\")\n",
    "    print(f\"   ‚Ä¢ AUC:       {auc_score:.4f}\")\n",
    "    \n",
    "    # Statistical significance conclusion\n",
    "    baseline_accuracy = max(y_test.mean(), 1 - y_test.mean())\n",
    "    improvement = accuracy - baseline_accuracy\n",
    "    improvement_pct = (improvement / baseline_accuracy) * 100\n",
    "    \n",
    "    print(f\"\\nüìä STATISTICAL SIGNIFICANCE:\")\n",
    "    print(f\"   ‚Ä¢ Baseline (majority class): {baseline_accuracy:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Improvement: {improvement:.4f} ({improvement_pct:.1f}%)\")\n",
    "    \n",
    "    # Feature analysis insights\n",
    "    tfidf = model.named_steps['tfidf']\n",
    "    try:\n",
    "        n_features = len(tfidf.get_feature_names_out())\n",
    "    except:\n",
    "        n_features = len(tfidf.get_feature_names())\n",
    "    \n",
    "    print(f\"\\nüîç FEATURE ANALYSIS:\")\n",
    "    print(f\"   ‚Ä¢ Total features: {n_features:,}\")\n",
    "    \n",
    "    # Practical significance\n",
    "    print(f\"\\nüí° PRACTICAL SIGNIFICANCE:\")\n",
    "    if accuracy > 0.85:\n",
    "        print(\"   ‚úÖ Model shows excellent practical utility for fake news detection\")\n",
    "    elif accuracy > 0.75:\n",
    "        print(\"   ‚ö†Ô∏è  Model shows good practical utility with room for improvement\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Model may have limited practical utility\")\n",
    "    \n",
    "    if precision > recall:\n",
    "        print(\"   ‚Ä¢ Model is more conservative (higher precision, lower recall)\")\n",
    "    else:\n",
    "        print(\"   ‚Ä¢ Model is more sensitive (higher recall, lower precision)\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for statistical analysis\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìä STATISTICAL ANALYSIS & EVALUATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load model and data\n",
    "    model, X_train, X_test, y_train, y_test = load_model_and_data()\n",
    "    \n",
    "    # 1. Hypothesis testing\n",
    "    y_pred, y_pred_proba = hypothesis_testing_performance(model, X_test, y_test)\n",
    "    \n",
    "    # 2. Confidence intervals\n",
    "    confidence_intervals_metrics(y_test, y_pred, y_pred_proba)\n",
    "    \n",
    "    # 3. Model assumption validation\n",
    "    validate_model_assumptions(model, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # 4. Feature importance analysis\n",
    "    feature_names, coefficients, perm_importance = analyze_feature_importance(\n",
    "        model, X_train, X_test, y_train, y_test\n",
    "    )\n",
    "    \n",
    "    # 5. Statistical significance of features\n",
    "    statistical_significance_features(model, X_test, y_test, feature_names)\n",
    "    \n",
    "    # 6. Comprehensive report\n",
    "    create_comprehensive_report(model, X_test, y_test, y_pred, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Statistical analysis completed!\")\n",
    "    print(f\"   Key findings saved in feature importance plots\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
